{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Prediction Results with the Sklearn MLP Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from FFNN.FFNN import FFNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (70000, 784)\n",
      "Shape y: (70000,)\n",
      "Train set: (56000, 784), Test set: (14000, 784)\n",
      "Shape y_train (one-hot): (56000, 10)\n",
      "Shape y_test (one-hot): (14000, 10)\n"
     ]
    }
   ],
   "source": [
    "# import dataset MNIST\n",
    "mnist = fetch_openml(name='mnist_784', version=1, as_frame=False)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "# convert label from string to integer\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "# print dataset info\n",
    "print(f\"Shape X: {X.shape}\")  # (70000, 784)\n",
    "print(f\"Shape y: {y.shape}\")  # (70000,)\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# normalize the data\n",
    "# pixel values are in range [0, 255], we normalize them to [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "num_classes = 10  # MNIST have 10 class (0-9)\n",
    "y_train_one_hot = np.eye(num_classes)[y_train]\n",
    "y_test_one_hot = np.eye(num_classes)[y_test]\n",
    "\n",
    "# print the shape of the one-hot encoded labels\n",
    "print(f\"Shape y_train (one-hot): {y_train_one_hot.shape}\")  # (56000, 10)\n",
    "print(f\"Shape y_test (one-hot): {y_test_one_hot.shape}\")    # (14000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.35535325\n",
      "Iteration 2, loss = 0.15636760\n",
      "Iteration 3, loss = 0.11103278\n",
      "Iteration 4, loss = 0.08572238\n",
      "Iteration 5, loss = 0.06890429\n",
      "Iteration 6, loss = 0.05620323\n",
      "Iteration 7, loss = 0.04737141\n",
      "Iteration 8, loss = 0.04007790\n",
      "Iteration 9, loss = 0.03450268\n",
      "Iteration 10, loss = 0.02965972\n",
      "Iteration 11, loss = 0.02509956\n",
      "Iteration 12, loss = 0.02102496\n",
      "Iteration 13, loss = 0.01739772\n",
      "Iteration 14, loss = 0.01450034\n",
      "Iteration 15, loss = 0.01197771\n",
      "Iteration 16, loss = 0.01007774\n",
      "Iteration 17, loss = 0.00855166\n",
      "Iteration 18, loss = 0.00700714\n",
      "Iteration 19, loss = 0.00551464\n",
      "Iteration 20, loss = 0.00491283\n",
      "Accuracy of MLPClassifier: 0.9774\n",
      "y_pred: [8 4 8 7 7 0 6 2 7 4 3 9 9 8 2 5 9 1 7 8]\n",
      "y_test: [8 4 8 7 7 0 6 2 7 4 3 9 9 8 2 5 9 1 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agilf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model MLPClassifier without optimisation (solver='lbfgs' or 'sgd' without momentum)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64),   # 2 hidden layer (128 dan 64 neuron)\n",
    "                    activation='relu',              # activation function ReLU\n",
    "                    solver='sgd',                   # SGD without momentum\n",
    "                    alpha=0.0001,                   # Regularisasi L2 \n",
    "                    batch_size=64,                  # Batch size 64\n",
    "                    learning_rate_init=0.1,         # Learning rate 0.1\n",
    "                    max_iter=20,                    # Maksimum 20 epoch\n",
    "                    momentum=0,                     # without momentum (no optimisation)\n",
    "                    n_iter_no_change=20,            # Early stopping if no improvement in 20 epochs\n",
    "                    random_state=42,\n",
    "                    verbose=True)\n",
    "\n",
    "# Training model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluasi akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of MLPClassifier: {accuracy:.4f}\")\n",
    "print(f\"y_pred: {y_pred[:20]}\")\n",
    "print(f\"y_test: {y_test[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [==================================================] 100.00%, Train Loss: 0.0701, Val Loss: 0.0838\n",
      "Training completed. Final Train Loss: 0.0701, Val Loss: 0.0838\n",
      "Accuracy of FFNN: 0.9641\n",
      "y_pred: [8 4 8 7 7 0 6 2 7 4 3 9 9 8 2 5 9 1 7 8]\n",
      "y_test: [8 4 8 7 7 0 6 2 7 4 3 9 9 8 2 5 9 1 7 8]\n"
     ]
    }
   ],
   "source": [
    "model1 = FFNN()\n",
    "\n",
    "# Add layers to the model\n",
    "model1.add_layer(784)\n",
    "model1.add_layer(128, activation_function='relu', initialization_method=\"he_normal\", seed=42)\n",
    "model1.add_layer(64, activation_function='relu', initialization_method=\"he_normal\", seed=42)\n",
    "model1.add_layer(10, activation_function='relu', initialization_method=\"he_normal\", seed=42)\n",
    "\n",
    "# Train the model\n",
    "model1.train(X_train, y_train_one_hot, X_test, y_test_one_hot, \n",
    "             learning_rate=0.1, batch_size=64, epochs=20, loss_function=\"MSE\", l2_lambda=0.0001,\n",
    "             verbose=1, seed=42)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model1.predict(X_test)\n",
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_label)\n",
    "print(f\"Accuracy of FFNN: {accuracy:.4f}\")\n",
    "print(f\"y_pred: {y_pred_label[:20]}\")\n",
    "print(f\"y_test: {y_test[:20]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
